#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SNR Performance Analysis
Analyze Signal-to-Noise Ratio improvements for all models vs classical filters
"""

import os
import numpy as np
import matplotlib.pyplot as plt
import _pickle as pickle
import pandas as pd
from datetime import datetime
import onnxruntime as ort
from digitalFilters.dfilters import IIR_test_Dataset, FIR_test_Dataset

def load_test_data(test_data_path='test_results_Vanilla L_nv1.pkl'):
    """Load test data"""
    with open(test_data_path, 'rb') as f:
        X_test, y_test, _ = pickle.load(f)
    return X_test, y_test

def calculate_snr(clean_signal, noisy_signal):
    """
    Calculate Signal-to-Noise Ratio in dB
    SNR = 10 * log10(P_signal / P_noise)
    """
    # Calculate signal power (variance of clean signal)
    signal_power = np.var(clean_signal)
    
    # Calculate noise power (variance of the difference)
    noise = noisy_signal - clean_signal
    noise_power = np.var(noise)
    
    # Avoid division by zero
    if noise_power == 0:
        return float('inf')
    
    # Calculate SNR in dB
    snr_db = 10 * np.log10(signal_power / noise_power)
    return snr_db

def calculate_snr_improvement(input_snr, output_snr):
    """Calculate SNR improvement in dB"""
    return output_snr - input_snr

def run_onnx_inference(model_path, X_test_batch):
    """Run inference on ONNX model"""
    session = ort.InferenceSession(model_path)
    input_name = session.get_inputs()[0].name
    output_name = session.get_outputs()[0].name
    
    X_input = X_test_batch.astype(np.float32)
    y_pred = session.run([output_name], {input_name: X_input})[0]
    
    return y_pred

def analyze_snr_performance():
    """Comprehensive SNR analysis of all models"""
    
    print("üìä SNR Performance Analysis")
    print("=" * 60)
    
    # Load test data
    X_test, y_test = load_test_data()
    
    # Use a subset for analysis (500 samples for speed)
    n_samples = 500
    X_subset = X_test[:n_samples]
    y_subset = y_test[:n_samples]
    
    print(f"Analyzing {n_samples} test samples...")
    
    # ONNX models to test
    onnx_models = {
        'Multibranch_LANLD': 'onnx_models/Multibranch_LANLD.onnx',
        'FCN_DAE': 'onnx_models/FCN_DAE.onnx',
        'Vanilla_NL': 'onnx_models/Vanilla_NL.onnx',
        'Multibranch_LANL': 'onnx_models/Multibranch_LANL.onnx',
        'DRNN': 'onnx_models/DRNN.onnx',
        'Vanilla_L': 'onnx_models/Vanilla_L.onnx'
    }
    
    # Store results
    snr_results = {}
    
    # Calculate input SNR (noisy vs clean)
    print("\nüìà Calculating input SNR...")
    input_snrs = []
    for i in range(n_samples):
        clean = y_subset[i, :, 0]
        noisy = X_subset[i, :, 0]
        snr = calculate_snr(clean, noisy)
        input_snrs.append(snr)
    
    input_snrs = np.array(input_snrs)
    avg_input_snr = np.mean(input_snrs)
    print(f"Average input SNR: {avg_input_snr:.2f} dB")
    
    # Test ONNX models
    print("\nüîÑ Testing ONNX models...")
    for model_name, model_path in onnx_models.items():
        if os.path.exists(model_path):
            print(f"  Testing {model_name}...")
            try:
                # Run inference
                y_pred = run_onnx_inference(model_path, X_subset)
                
                # Calculate output SNRs
                output_snrs = []
                snr_improvements = []
                
                for i in range(n_samples):
                    clean = y_subset[i, :, 0]
                    denoised = y_pred[i, :, 0]
                    
                    # Output SNR (clean vs denoised)
                    output_snr = calculate_snr(clean, denoised)
                    output_snrs.append(output_snr)
                    
                    # SNR improvement
                    improvement = calculate_snr_improvement(input_snrs[i], output_snr)
                    snr_improvements.append(improvement)
                
                snr_results[model_name] = {
                    'output_snrs': np.array(output_snrs),
                    'snr_improvements': np.array(snr_improvements),
                    'avg_output_snr': np.mean(output_snrs),
                    'avg_improvement': np.mean(snr_improvements),
                    'std_improvement': np.std(snr_improvements)
                }
                
                print(f"    ‚úÖ Avg output SNR: {np.mean(output_snrs):.2f} dB")
                print(f"    ‚úÖ Avg improvement: {np.mean(snr_improvements):.2f} dB")
                
            except Exception as e:
                print(f"    ‚ùå Error: {e}")
        else:
            print(f"  ‚ùå Model not found: {model_path}")
    
    # Test classical filters
    print("\nüîß Testing classical filters...")
    
    # IIR Filter
    print("  Testing IIR filter...")
    try:
        dataset = [None, None, X_subset, y_subset]
        _, _, y_iir = IIR_test_Dataset(dataset)
        
        output_snrs_iir = []
        snr_improvements_iir = []
        
        for i in range(n_samples):
            clean = y_subset[i, :, 0]
            filtered = y_iir[i, :, 0]
            
            output_snr = calculate_snr(clean, filtered)
            output_snrs_iir.append(output_snr)
            
            improvement = calculate_snr_improvement(input_snrs[i], output_snr)
            snr_improvements_iir.append(improvement)
        
        snr_results['IIR_Filter'] = {
            'output_snrs': np.array(output_snrs_iir),
            'snr_improvements': np.array(snr_improvements_iir),
            'avg_output_snr': np.mean(output_snrs_iir),
            'avg_improvement': np.mean(snr_improvements_iir),
            'std_improvement': np.std(snr_improvements_iir)
        }
        
        print(f"    ‚úÖ Avg output SNR: {np.mean(output_snrs_iir):.2f} dB")
        print(f"    ‚úÖ Avg improvement: {np.mean(snr_improvements_iir):.2f} dB")
        
    except Exception as e:
        print(f"    ‚ùå IIR Error: {e}")
    
    # FIR Filter (test on smaller subset due to speed)
    print("  Testing FIR filter (100 samples only - very slow)...")
    try:
        n_fir = 100
        dataset_fir = [None, None, X_subset[:n_fir], y_subset[:n_fir]]
        _, _, y_fir = FIR_test_Dataset(dataset_fir)
        
        output_snrs_fir = []
        snr_improvements_fir = []
        
        for i in range(n_fir):
            clean = y_subset[i, :, 0]
            filtered = y_fir[i, :, 0]
            
            output_snr = calculate_snr(clean, filtered)
            output_snrs_fir.append(output_snr)
            
            improvement = calculate_snr_improvement(input_snrs[i], output_snr)
            snr_improvements_fir.append(improvement)
        
        snr_results['FIR_Filter'] = {
            'output_snrs': np.array(output_snrs_fir),
            'snr_improvements': np.array(snr_improvements_fir),
            'avg_output_snr': np.mean(output_snrs_fir),
            'avg_improvement': np.mean(snr_improvements_fir),
            'std_improvement': np.std(snr_improvements_fir)
        }
        
        print(f"    ‚úÖ Avg output SNR: {np.mean(output_snrs_fir):.2f} dB")
        print(f"    ‚úÖ Avg improvement: {np.mean(snr_improvements_fir):.2f} dB")
        
    except Exception as e:
        print(f"    ‚ùå FIR Error: {e}")
    
    return snr_results, input_snrs, avg_input_snr

def display_snr_results(snr_results, avg_input_snr):
    """Display comprehensive SNR results"""
    
    print(f"\n" + "="*80)
    print(f"üèÜ SNR PERFORMANCE COMPARISON")
    print(f"="*80)
    
    print(f"\nüìä SNR ANALYSIS RESULTS:")
    print(f"Average Input SNR: {avg_input_snr:.2f} dB")
    print(f"\n{'Model':<20} {'Output SNR':<12} {'SNR Improve':<12} {'Std Dev':<10} {'Samples':<8}")
    print("-" * 70)
    
    # Sort by SNR improvement (higher is better)
    sorted_results = sorted(snr_results.items(), key=lambda x: x[1]['avg_improvement'], reverse=True)
    
    for i, (model_name, results) in enumerate(sorted_results):
        rank_emoji = "ü•á" if i == 0 else "ü•à" if i == 1 else "ü•â" if i == 2 else f"{i+1:2d}"
        
        print(f"{rank_emoji} {model_name:<18} "
              f"{results['avg_output_snr']:<12.2f} "
              f"{results['avg_improvement']:<12.2f} "
              f"{results['std_improvement']:<10.2f} "
              f"{len(results['output_snrs']):<8}")
    
    # Performance insights
    print(f"\nüéØ KEY SNR INSIGHTS:")
    
    # Best performer
    best_model = sorted_results[0]
    print(f"   üèÜ Best SNR Improvement: {best_model[0]} (+{best_model[1]['avg_improvement']:.2f} dB)")
    
    # Classical vs Deep Learning comparison
    classical_models = [(k, v) for k, v in sorted_results if 'Filter' in k]
    dl_models = [(k, v) for k, v in sorted_results if 'Filter' not in k]
    
    if classical_models and dl_models:
        best_classical = max(classical_models, key=lambda x: x[1]['avg_improvement'])
        best_dl = max(dl_models, key=lambda x: x[1]['avg_improvement'])
        
        improvement_ratio = best_dl[1]['avg_improvement'] / best_classical[1]['avg_improvement'] if best_classical[1]['avg_improvement'] > 0 else float('inf')
        
        print(f"   üìà Deep Learning SNR Advantage:")
        print(f"      Best Classical: {best_classical[0]} (+{best_classical[1]['avg_improvement']:.2f} dB)")
        print(f"      Best Deep Learning: {best_dl[0]} (+{best_dl[1]['avg_improvement']:.2f} dB)")
        if improvement_ratio != float('inf'):
            print(f"      Improvement Ratio: {improvement_ratio:.1f}x better")
    
    # SNR categories
    print(f"\nüìä SNR IMPROVEMENT CATEGORIES:")
    excellent = [k for k, v in sorted_results if v['avg_improvement'] > 10]
    good = [k for k, v in sorted_results if 5 <= v['avg_improvement'] <= 10]
    moderate = [k for k, v in sorted_results if 0 <= v['avg_improvement'] < 5]
    poor = [k for k, v in sorted_results if v['avg_improvement'] < 0]
    
    if excellent:
        print(f"   üåü Excellent (>10 dB): {', '.join(excellent)}")
    if good:
        print(f"   ‚úÖ Good (5-10 dB): {', '.join(good)}")
    if moderate:
        print(f"   ‚ö†Ô∏è  Moderate (0-5 dB): {', '.join(moderate)}")
    if poor:
        print(f"   ‚ùå Poor (<0 dB): {', '.join(poor)}")

def create_snr_visualizations(snr_results, input_snrs, avg_input_snr):
    """Create comprehensive SNR visualizations"""
    
    print(f"\nüìä Creating SNR visualizations...")
    
    # Create 2x2 subplot for comprehensive analysis
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # Plot 1: SNR Improvement Comparison
    models = list(snr_results.keys())
    improvements = [snr_results[m]['avg_improvement'] for m in models]
    colors = ['blue' if 'Filter' not in m else 'red' for m in models]
    
    bars1 = ax1.bar(range(len(models)), improvements, color=colors, alpha=0.7)
    ax1.set_xlabel('Models')
    ax1.set_ylabel('SNR Improvement (dB)')
    ax1.set_title('SNR Improvement Comparison', fontweight='bold')
    ax1.set_xticks(range(len(models)))
    ax1.set_xticklabels([m.replace('_', '\n') for m in models], rotation=45, ha='right')
    ax1.grid(True, alpha=0.3)
    ax1.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    
    # Add value labels
    for bar, value in zip(bars1, improvements):
        ax1.text(bar.get_x() + bar.get_width()/2, 
                bar.get_height() + (0.5 if value >= 0 else -1),
                f'{value:.1f}', ha='center', va='bottom' if value >= 0 else 'top', fontsize=9)
    
    # Plot 2: Output SNR Comparison
    output_snrs = [snr_results[m]['avg_output_snr'] for m in models]
    bars2 = ax2.bar(range(len(models)), output_snrs, color=colors, alpha=0.7)
    ax2.set_xlabel('Models')
    ax2.set_ylabel('Output SNR (dB)')
    ax2.set_title('Output SNR Comparison', fontweight='bold')
    ax2.set_xticks(range(len(models)))
    ax2.set_xticklabels([m.replace('_', '\n') for m in models], rotation=45, ha='right')
    ax2.grid(True, alpha=0.3)
    ax2.axhline(y=avg_input_snr, color='green', linestyle='--', alpha=0.7, label=f'Input SNR ({avg_input_snr:.1f} dB)')
    ax2.legend()
    
    # Add value labels
    for bar, value in zip(bars2, output_snrs):
        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                f'{value:.1f}', ha='center', va='bottom', fontsize=9)
    
    # Plot 3: SNR Distribution (Box Plot)
    snr_data = [snr_results[m]['snr_improvements'] for m in models]
    bp = ax3.boxplot(snr_data, labels=[m.replace('_', '\n') for m in models], patch_artist=True)
    
    # Color the boxes
    for patch, color in zip(bp['boxes'], colors):
        patch.set_facecolor(color)
        patch.set_alpha(0.7)
    
    ax3.set_xlabel('Models')
    ax3.set_ylabel('SNR Improvement (dB)')
    ax3.set_title('SNR Improvement Distribution', fontweight='bold')
    ax3.grid(True, alpha=0.3)
    ax3.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    plt.setp(ax3.get_xticklabels(), rotation=45, ha='right')
    
    # Plot 4: Input vs Output SNR Scatter
    for model_name, results in snr_results.items():
        color = 'blue' if 'Filter' not in model_name else 'red'
        marker = 'o' if 'Filter' not in model_name else 's'
        
        # Use subset of points for clarity
        n_points = min(50, len(results['output_snrs']))
        indices = np.random.choice(len(results['output_snrs']), n_points, replace=False)
        
        if model_name.startswith('FIR'):
            # FIR has fewer samples, use all
            input_subset = input_snrs[:len(results['output_snrs'])]
            output_subset = results['output_snrs']
        else:
            input_subset = input_snrs[indices]
            output_subset = results['output_snrs'][indices]
        
        ax4.scatter(input_subset, output_subset, 
                   c=color, marker=marker, alpha=0.6, s=30, label=model_name.replace('_', ' '))
    
    # Add diagonal line (no improvement)
    min_snr = min(input_snrs.min(), min([r['output_snrs'].min() for r in snr_results.values()]))
    max_snr = max(input_snrs.max(), max([r['output_snrs'].max() for r in snr_results.values()]))
    ax4.plot([min_snr, max_snr], [min_snr, max_snr], 'k--', alpha=0.5, label='No Improvement')
    
    ax4.set_xlabel('Input SNR (dB)')
    ax4.set_ylabel('Output SNR (dB)')
    ax4.set_title('Input vs Output SNR', fontweight='bold')
    ax4.grid(True, alpha=0.3)
    ax4.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    plt.tight_layout()
    plt.savefig('snr_analysis_comprehensive.png', dpi=150, bbox_inches='tight')
    print("‚úÖ SNR analysis plot saved: snr_analysis_comprehensive.png")
    
    # Create a focused comparison plot
    create_snr_focused_plot(snr_results, avg_input_snr)

def create_snr_focused_plot(snr_results, avg_input_snr):
    """Create a focused SNR comparison plot"""
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
    
    # Sort models by SNR improvement
    sorted_models = sorted(snr_results.items(), key=lambda x: x[1]['avg_improvement'], reverse=True)
    
    models = [m[0] for m in sorted_models]
    improvements = [m[1]['avg_improvement'] for m in sorted_models]
    output_snrs = [m[1]['avg_output_snr'] for m in sorted_models]
    
    colors = ['blue' if 'Filter' not in m else 'red' for m in models]
    
    # Plot 1: SNR Improvement (sorted)
    bars1 = ax1.bar(range(len(models)), improvements, color=colors, alpha=0.7)
    ax1.set_xlabel('Models (Ranked by Performance)')
    ax1.set_ylabel('SNR Improvement (dB)')
    ax1.set_title('SNR Improvement Ranking', fontweight='bold', fontsize=14)
    ax1.set_xticks(range(len(models)))
    ax1.set_xticklabels([m.replace('_', '\n') for m in models], rotation=45, ha='right')
    ax1.grid(True, alpha=0.3)
    ax1.axhline(y=0, color='black', linestyle='--', alpha=0.5, label='No Improvement')
    
    # Add value labels and ranking
    for i, (bar, value) in enumerate(zip(bars1, improvements)):
        rank = "ü•á" if i == 0 else "ü•à" if i == 1 else "ü•â" if i == 2 else f"{i+1}"
        ax1.text(bar.get_x() + bar.get_width()/2, 
                bar.get_height() + (0.5 if value >= 0 else -1),
                f'{rank}\n{value:.1f} dB', ha='center', va='bottom' if value >= 0 else 'top', 
                fontsize=9, fontweight='bold')
    
    ax1.legend()
    
    # Plot 2: Before vs After SNR
    x_pos = np.arange(len(models))
    width = 0.35
    
    input_snr_values = [avg_input_snr] * len(models)  # Same input for all
    
    bars2a = ax2.bar(x_pos - width/2, input_snr_values, width, 
                    label='Input SNR', color='gray', alpha=0.7)
    bars2b = ax2.bar(x_pos + width/2, output_snrs, width,
                    label='Output SNR', color=colors, alpha=0.7)
    
    ax2.set_xlabel('Models (Ranked by Performance)')
    ax2.set_ylabel('SNR (dB)')
    ax2.set_title('Before vs After SNR Comparison', fontweight='bold', fontsize=14)
    ax2.set_xticks(x_pos)
    ax2.set_xticklabels([m.replace('_', '\n') for m in models], rotation=45, ha='right')
    ax2.grid(True, alpha=0.3)
    ax2.legend()
    
    # Add improvement arrows
    for i, (input_val, output_val, improvement) in enumerate(zip(input_snr_values, output_snrs, improvements)):
        if improvement > 0:
            ax2.annotate('', xy=(i + width/2, output_val), xytext=(i - width/2, input_val),
                        arrowprops=dict(arrowstyle='->', color='green', lw=2))
            ax2.text(i, max(input_val, output_val) + 1, f'+{improvement:.1f}dB', 
                    ha='center', va='bottom', fontweight='bold', color='green')
    
    plt.tight_layout()
    plt.savefig('snr_focused_comparison.png', dpi=150, bbox_inches='tight')
    print("‚úÖ Focused SNR comparison saved: snr_focused_comparison.png")

def save_snr_results_csv(snr_results, avg_input_snr):
    """Save SNR results to CSV"""
    
    data = []
    for model_name, results in snr_results.items():
        data.append({
            'Model': model_name,
            'Type': 'ONNX' if 'Filter' not in model_name else 'Classical',
            'Input_SNR_dB': avg_input_snr,
            'Output_SNR_dB': results['avg_output_snr'],
            'SNR_Improvement_dB': results['avg_improvement'],
            'SNR_Improvement_Std': results['std_improvement'],
            'Test_Samples': len(results['output_snrs'])
        })
    
    df = pd.DataFrame(data)
    df = df.sort_values('SNR_Improvement_dB', ascending=False)
    
    csv_filename = f'snr_analysis_results_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
    df.to_csv(csv_filename, index=False)
    
    print(f"‚úÖ SNR results saved to: {csv_filename}")
    return csv_filename

def main():
    """Main SNR analysis function"""
    
    print("üîä DeepFilter SNR Performance Analysis")
    print("=" * 60)
    
    try:
        # Run comprehensive SNR analysis
        snr_results, input_snrs, avg_input_snr = analyze_snr_performance()
        
        # Display results
        display_snr_results(snr_results, avg_input_snr)
        
        # Create visualizations
        create_snr_visualizations(snr_results, input_snrs, avg_input_snr)
        
        # Save results to CSV
        csv_file = save_snr_results_csv(snr_results, avg_input_snr)
        
        print(f"\nüéâ SNR ANALYSIS COMPLETE!")
        print(f"Generated files:")
        print(f"   - snr_analysis_comprehensive.png: Complete 4-panel SNR analysis")
        print(f"   - snr_focused_comparison.png: Focused ranking and before/after comparison")
        print(f"   - {csv_file}: Detailed numerical results")
        print(f"\nüìä Key Finding: ONNX models provide significant SNR improvements over classical filters!")
        
    except Exception as e:
        print(f"‚ùå Error in SNR analysis: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
